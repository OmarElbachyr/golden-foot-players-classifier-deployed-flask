{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cead507",
   "metadata": {},
   "source": [
    "<h2 style='color:green' align='center'>Golden Foot Players Image Classification SVM Model<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e426346f",
   "metadata": {},
   "source": [
    "### Importing the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2803d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pywt\n",
    "import cv2   \n",
    "import pickle \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde0792",
   "metadata": {},
   "source": [
    "<h3 style='color:purple'>(1) Preprocessing: Detect face and eyes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./haarcascades/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d74ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_image_if_2_eyes(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        if len(eyes) >= 2:\n",
    "            return roi_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d83e8c",
   "metadata": {},
   "source": [
    "<h3 style='color:purple'>(2) Preprocessing: Crop the facial region of the image</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../dataset/\"\n",
    "path_to_cr_data = \"../dataset/cropped-images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc9412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dirs store folders names for each player\n",
    "img_dirs = []\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bc508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cropped-images folder exists remove it, if not create it.\n",
    "import shutil\n",
    "if os.path.exists(path_to_cr_data):\n",
    "     shutil.rmtree(path_to_cr_data)\n",
    "os.mkdir(path_to_cr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324d62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_dirs = []\n",
    "celebrity_file_names_dict = {}\n",
    "\n",
    "for img_dir in img_dirs:\n",
    "    count = 1\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    print(celebrity_name)\n",
    "    \n",
    "    celebrity_file_names_dict[celebrity_name] = []\n",
    "    \n",
    "    for entry in os.scandir(img_dir):\n",
    "#         print(entry)\n",
    "        roi_color = get_cropped_image_if_2_eyes(entry.path)\n",
    "        \n",
    "        # test if face and two eyes are clearly visible\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_to_cr_data + celebrity_name   # ./dataset/cropped/Mohamed_salah\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_image_dirs.append(cropped_folder)\n",
    "                print(\"Generating cropped images in folder: \", cropped_folder)\n",
    "                \n",
    "            cropped_file_name = celebrity_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name \n",
    "            \n",
    "            cv2.imwrite(cropped_file_path, roi_color)\n",
    "            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrity_file_names_dict['pele']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67be1fb",
   "metadata": {},
   "source": [
    "### LBP transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed8f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "import numpy as np\n",
    "\n",
    "def lbp_features(img, radius=1, sampling_pixels=8):\n",
    "    \n",
    "    # LBP operates in single channel images so if RGB images are provided\n",
    "    # we have to convert it to grayscale\n",
    "    if (len(img.shape) > 2):\n",
    "        img = img.astype(float)\n",
    "        # RGB to grayscale convertion using Luminance\n",
    "        img = img[:,:,0]*0.3 + img[:,:,1]*0.59 + img[:,:,2]*0.11\n",
    "\n",
    "    # converting to uint8 type for 256 graylevels\n",
    "    img = img.astype(np.uint8)\n",
    "    \n",
    "    # normalize values can also help improving description\n",
    "    i_min = np.min(img)\n",
    "    i_max = np.max(img)\n",
    "    if (i_max - i_min != 0):\n",
    "        img = (img - i_min)/(i_max-i_min)\n",
    "    \n",
    "    # compute LBP\n",
    "    lbp = feature.local_binary_pattern(img, sampling_pixels, radius, method=\"uniform\")\n",
    "    \n",
    "    # LBP returns a matrix with the codes, so we compute the histogram\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, sampling_pixels + 3), range=(0, sampling_pixels + 2))\n",
    "\n",
    "    # normalization\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    # return the histogram of Local Binary Patterns\n",
    "    return hist\n",
    "\n",
    "def Euclidean_distance(p, q):\n",
    "    dist = np.sqrt(np.sum(np.square(p-q)))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf7263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {}\n",
    "count = 0\n",
    "for celebrity_name in celebrity_file_names_dict.keys():\n",
    "    class_dict[celebrity_name] = count\n",
    "    count = count + 1\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for celebrity_name, training_files in celebrity_file_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        scalled_img = cv2.resize(img, (32, 32))\n",
    "        \n",
    "        img_lbp = lbp_features(img)\n",
    "        scalled_lbp = cv2.resize(img_lbp, (32, 32))\n",
    "        \n",
    "        combined_img  = np.vstack((scalled_img.reshape(32*32*3, 1), scalled_lbp.reshape(32*32, 1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(class_dict[celebrity_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f10ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "32*32*3 + 32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X), 4096).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41f0c44",
   "metadata": {},
   "source": [
    "<h3 style='color:purple'>(3) Training: SVM model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd4a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2200d01",
   "metadata": {},
   "source": [
    "<h3 style='color:purple'>(4) Training: SVM kernel tuning with heuristic finetuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5456310",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec29fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789da4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimators['svm'].score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81ac8a",
   "metadata": {},
   "source": [
    "### Saving the most performant model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(best_estimators['svm'], 'svm-model.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "72251c09017d1717317eeb23febad64bc9c50b54090a3faa149e721e7223e565"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
